__1.0 HCI__
Human-computer interaction(HCI) is the field of how people and computers communicate to each other. The term was developed by Stuart Card, Thomas P. Moran, Allen Newell in 1980 however it became widely known only in 1983 because of their book; _The Psychology of Human-Computer Interaction_. Both the term and the field has two sides; one side are the computers, machines that is about: computer graphics, operating systems, programming languages, development areas, the other side is the human part such as industrial design, ergonomics, communication, cognitive psychology. Because of this two side there are many aspects of the communication, but I'm not going to discuss all of them, what I'm interested in is the input and the output or more precisely the actions, reactions that happen when people interact with computers. Something that for over 3 decades – since the release of Xerox Star(1981), Apple Lisa(1982) and the Machintosh(1984) – did not changed in it's basics. With the invention of the graphical user interface(GUI) – that enabled direct manipulation of graphical objects on a screen – not just professionals or hobbyists were able to use computers but everyone. Because of the ease of use that graphical user interfaces provided and the desktop metaphor that linked the real world to the digital, made it easy to learn, how to use software, provided many affordances, previous knowledge that designers could build on when they wanted to build something in the digital world. This way when users turned on their computers  they faced softwares that looked familiar, what reduced learning, helped adaptation. Overall the user experience was better because of the skeuomorphic design – emulation of physical objects in the digital world.

Three decades later; users, designers still heavily rely on skeuomorphic design, GUIs are the best way to interact with computers, input methods are the same and the output in most cases are colorful pixels / some sound.

__1.1 Hard and Soft__
Separation of the hardware and software resulted in many things.  Manipulation of the digital world was easy, the only constrains it had were bound to the screen. How large is it, what's the resolution, how many color is it displaying? Where can users take their screen(s), is it foldable or not? Physical objects on the other hand are much harder to manipulate, it requires many things and creating new materials, manufacturing processes takes much more time, money, than writing software. As a result of this separation software developed in a different pace and hardware were unable to follow it for many years. It took several years to shrink down the size of the 'hard' part, yet still provide enough computing power, long battery life, ergonomic input. After the race for miniaturization in the 80's and 90's, size of the devices hit a limit from which point on size was not a question of capability, technological problem anymore but the question of design. Thanks to the miniaturization computers went from rooms to bags and eventually to pockets. Even further with google glass or with digital contact lenses – that were developed at the Washington University in 2008.

As an unpredicted phenomenon of the miniaturization, computers moved not just into our pockets, but into our existing artifacts, creating many more objects along the way. This step was the first in the process to seamlessly integrate the digital world into the physical. A process that today we call ubiquitous computing – a concept where computers and user interfaces are not bound by screen, nor the location of a device, because everything, everywhere can be a screen, a user interface. Wearable computers try to achieve the same thing with a different approach. Embedding electronics into fabrics to create  clothes that are self-aware, can measure different things about it's wearer, act as a user interface or even as a display. All this effort to reach an ideal state were hard(ware) and soft(ware) are still separated. The soft part can live outside from the screen creating more meaningful, context aware feedbacks than showing some pixels. The hard part is not a piece of rigid plastic or metal, rather something that users can fold, squeeze, stretch, bend, shape, transform into something that they need at the moment. The ultimate goal is to create many devices and an environment where users can interact with the computer as they would interact with any other object and where the computer will give a a content and context aware response to the usage.

__1.1.1 Soft__ - _soft = brain (senses)_
> _Soft; easy to mold, cut, compress, or fold. Not hard or firm to touch. It has a pleasing quality involving a subtle effect or contrast rather than sharp definition._
In many ways software is a soft thing. It's easy to manipulate and change in many ways. Touching a software can feel hard or firm to our fingers but not to our brain. Animation, texture, skeuomorphic elements, shadow, field of depth are visual clues to create a feel in users, to indicate what is active or inactive, what they are able to manipulate etc.. The separation between software and hardware created a distance in users. Look, feel and behavior of the software is not bound to the look, feel or behavior of the hardware. Buttons, pointing– or other input devices are created for general usage, there is very few hardware that is designed for a specific task. Software on the other hand are always created for specific usage. A certain distance because of this formed in users; that means using a software is not defined be what they feel with their fingers, how they have to manipulate an object but what they see on the screen. Of course there are software on many digital devices what users can experience without a display; elevators, kitchen supply, cars and many more other tools. Number of these tools is high, yet the interaction rate is low, feedback is subtle, output is usually not personal and have nothing to do with our digital world. As a result interactions with such devices are not interesting. After learning to operate them, until the point it's not working properly users do not care. Displays on the other hand are much more interesting. One reason of this is that displays are filled with content. Updates from our friends, news about the world, emails, pictures, videos etc.. Something that is more important and personal than a toast in the morning or the automatically working lights after nightfall.

The preference of the visual things what in this case is the display can be explained with evolutionary principals and the fact the humans are visual creatures. Smell, taste, the feel of touch, sounds were and are important as well, but visual cues  are far more important when it comes to hunting/survival. This dependency is so strong that constant visual feedback is needed to perform gestures, learn things, operate something. Building on this dependency the first softwares – and many, even today – mimicking physical objects and their behavior that i called skeuomorphic earlier. A practice to trick users mind creating an  illusion that clicking with a mouse, pushing buttons or typing commands on a keyboard somehow should feel the same as manipulation of physical things in the real world.

__1.1.2 Hard__ - _hard = body (bone, skin)_
> _Hard; solid, firm, and resistant to pressure. Not easily broken, bent, or pierced._
In the world of computers and digital devices hardware always meant and still means, the actual physical thing users need to own/have in order, to interact with the software. A shell that contains all the necessary electronic components, some kind of an input possibility; to give commands to the software, and of course some kind of an output, what could be anything; one led or many (screen), a vibration motor, speaker and so on. For over three decades computers and digital devices were always something hard. A hard shell to protect electronic components. This quality defined not just the look but the materials devices were made from. During the 80's and 90's and the process of miniaturization plastic was the most commonly used material. It's cheap, easy to create many forms from it, not conductive, can have a soft touch regardless it's rigidness. Only premium products were using other materials, such as; wood, leather, metal, etc.. But these materials are only used to coat the inner – rigid – part of digital products. Although there are many great examples that show, even the hardware can be soft. Foldable displays for example, are long promised products of future computing, but there are plastic–, rubber based devices as well that are durable, yet users are able to manipulate them. Paper with embedded electronics, conductive ink and fabric, touchscreen that is able to simulate 3D geometric features, such as; bumps, edges, texture etc., edible user interfaces, interfaces using plants, living things as input, wearable technology. A few example where the rigidness of digital devices are broken in favor of something that is more tactile and expressive during usage. The problem with these examples is that they rarely make their way into the consumers hand, they exist in research laboratories, art galleries or other places where latest technologies and new approaches to HCI is important.

Disappearing computers was and still an unpredicted phenomenon of the miniaturization but it's a great approach. Usage of sensors and embedding hardware in everyday objects can create a seamless connection between physical and digital. The first step is that users will be able to control various softwares with dedicated objects around them. Second step is to create objects that are not just remote controls but can have different impact on users digital world. Third step is when the digital world is making it's way to the physical. With examples mentioned earlier – like foldable displays, touch-screens that can render 3D geometric features etc. – and things like 3D printers, wireless connection of many devices, smart objects, sensors the third step is already happening but in slightly different way than imagined.

__1.2 Input__















***
> If we want to understand how interactive systems work, what input methods are there, what is possible as an output, what gestures are and why are we interacting with computers and digital devices the way we do the field of interaction design is what we need.

> Hands feel things, and hands manipulate things.